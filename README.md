# Provision and run monitoring script inside Kubernetes
-------------------------
### Task:

Run a simple script inside Kubernetes cluster

### Description:

In order to perform the task, I had been thinking to deploy some script inside the Kubernetes that may have some practical use.
Therefore, I've decided to deploy the script that will notify admin via email that someone has tried to brute-force TFTP service running on a Node of Kubernetes cluster.
For this purpose, I've used CronJob controller that allows running script inside pods periodically according to a predefined schedule.

### Prerequsites:

To make the script work the following things are essential:

1. Linux test environment.
2. Time-zone on Host machine that will run Kubernetes deployment should have the same timezone as Kubernetes deployment (minikube VM in my case).
3. Simple TFTP server is configured on the host machine where Kubernetes will be deployed.
4. Configured TFTP server firewall. Can be done in the following way:
```
# Define new chain:
sudo iptables -N tftp_protector
# Insert chain into default INPUT
sudo iptables -A INPUT ! -i lo -p udp -m udp --dport 69 -j tftp_protector
# accept avarage 10 TFTP connections per minute (--limit 10/min), drop connections when limit is reached.
# 10 simulateous connections are allowed by (--limit-burst 10)
# if connection rate is more than 10/min, log this messages to syslog and then, reject:
sudo iptables -A tftp_protector -p udp -m udp --dport 69 -m limit --limit 10/min --limit-burst 10 -j ACCEPT
sudo iptables -A tftp_protector -p udp -m udp --dport 69 -m limit --limit 11/min --limit-burst 10 -j LOG --log-prefix "IPTables-TFTP-Rejected: " --log-level 4
sudo iptables -A tftp_protector -p udp -m udp --dport 69 -j REJECT --reject-with icmp-port-unreachable
```

5. Simple SMTP server that will accept emails generated by monitoring script.
6. Monitoring script on your host machine:
```
#!/bin/sh

# Define variables:
# nlines - number of lines script should check from the end of the file for any detected attempts to connect to TFTP over defined limit
# Modify nlines in conjuction with schedule of the script depending on the frequency of log messages writes to syslog
# log_file - log file that should be checked
# monitor_log_file - file where script should redirect its output
nlines=100
log_file="/host_logs/syslog"
monitor_log_file="/host_logs/mon_logs/tftp_monitor.log"

# Log function
function log {
    msg=$1
    # Check if $monitor_log_file is available for write
	if [ -w "${monitor_log_file}" ]; then
        echo "$(date +"%b %d %T"): ${msg}" | tee -a $monitor_log_file
    else
        echo "$(date +"%b %d %T"): ${msg}"
    fi
}

log "Start script $0"

# Check if $log_file can be read
if [ -r "$log_file" ]; then
    log "Checked file: ${log_file} exists. Proceed with TFTP check."
else
    log "Checked file: ${log_file} is not available for read. Stop execution."
    exit 1 #here cronjob pod will get Error status and will be restarted by controller according to restartPolicy specified in job template
fi

# Check if there were any attempts to access TFTP on host machine over the allowed rate in the last N lines of log:
tftp_stats=$(\
    tail -${nlines} ${log_file}|\
    grep "IPTables-TFTP-Rejected"|\
    awk -F "SRC=" '{print $2}'|\
    sed '/^$/d'|\
    awk -F " DST=" '{print $1}'|\
    sort|uniq -c|sort -k 1\
)

# If brute-force attempts have not been detected, just print log message
if [ -z "$tftp_stats" ]; then
    log "Brute-force atteampts have not been detected!"
# Else send monitoring alert
else
    log "Brute-force atteampts have been detected!"
    log "Here is the statistics:"
	log "$tftp_stats"

    ## REMOTE_SMTP_IP, REMOTE_SMTP_PORT, NODE_IP may be different from node to node where the script is deployed, so decided to put this as env variables
    ##  - but the main reason is show that I've also considered how variables can be passed to scripts in Kubernetes

    # Check for remote_smtp availability
	log "Checking if remote SMPT ${REMOTE_SMTP_IP}:${REMOTE_SMTP_PORT} is available."
    nc -zv $REMOTE_SMTP_IP $REMOTE_SMTP_PORT

    # If remote SMTP is available, send email alert
    if [ $? -eq 0 ]; then
        log "Composing and sending email alert."

        # Compose and send email:
        email_to="admin-kubernetes@gmail.com"
        email_from="root@tftp-monitor"
        sbj="TFPT brute-force is detected on $NODE_IP"

        sendmail -S ${REMOTE_SMTP_IP}:${REMOTE_SMTP_PORT} $email_to <<EOF
From:$email_from
Subject:$sbj
Hi,

Someone tried to brute-force TFTP connection on ${NODE_IP}.

Here is the report:
$tftp_stats
EOF

        # If sendmail fails due to some reason, we need to try re-executing our check immidiately
        if [ $? -ne 0 ]; then
            log "Sending email failed due to some reason."
			exit 1
		else
		    log "Email has been sent."
        fi
    # Else skip sending alert
    else
        log "Remote SMTP server ${remote_smtp} is not available. Alert cannot be sent."
		exit 1 #here cronjob pod will get Error status and will be restarted by controller according to restartPolicy specified in job template
		       #error code here is essential, because admin won't now about bruteforce in case remote SMTP is not available. Thus, kubernetes should try to retry script to notify admin.
    fi
fi
```

**Variables that can be changed:**

```
# Number of lines script should check from the end of the file for any detected attempts to connect to TFTP over defined limit
# Modify nlines in conjuction with schedule of the script depending on the frequency of log messages writes to syslog
nlines=100

# File on host machine that shell be checked by the script
# you should specify here the mount pass of the host directory inside of Pod/container
log_file="/host_logs/syslog"
 
# File on host machine that will be used by the script to store all log messages:
# you should specify here the mount pass of the host directory inside of Pod/container
monitor_log_file="/host_logs/mon_logs/tftp_monitor.log"
 
# Email that shell receive monitoring alerts:
email_to="admin-kubernetes@gmail.com"
 
# Email From that will be used to send alert via email
email_from="root@tftp-monitor"
 
# Email alert subject:
sbj="TFPT brute-force detected"
 
# Env variables that are passed to the Pod that will run script (can be specified in yaml file of Pod/container, you will see later).
# IP address of remote SMTP server that will sent emails generated by script to the recepient via SMTP:
REMOTE_SMTP_IP
# Port of remote SMTP server that will send emails generated by script to the recepient via SMTP:
REMOTE_SMTP_PORT
# IP address of the Kubernetes node where script is deployed inside of Pod:
NODE_IP
```

**Monitoring script workflow:**

1. Define number of lines that should be checked from the end of the system log file.
2. Check if the system log file that script is going to check for TFTP-Rejected messages is available (mounted into Pod and can be opened for reading).
Finish with error if file is not available, so Kubernetes will restart Pod where script is running.
3. Extract data from log and look for any appearance of LOG messages about TFTP connection rejection from kernel:
- script adds information about source IP addresses and counts of rejected connections;
- script takes only last $nlines lines from the syslog file in order to speed up the lookup.
  
> NOTE: If in your case script cannot find brute-force attempt, however, you are seeing this attempts in syslog it may be related to the fact that your Host OS logs a lot of messages per second to the system log and script simply cannot find attempts in N last lines of system log file.
> In this case consider increasing $nlines parameter, so script will be able to find brute-force attempts in the log
  
4. Script evaluates if any TFTP connections were rejected due to the fact that TFTP connections rate exceeds the limit defined in firewall:
- if any attempts were found script composes email with report and send it to external email address:
> NOTE: if remote SMTP server for sending alert to recepient is not available, script exits with error, so, Kubernetes will restart the Job immidiately;
- if attempts are not detected script prints appropriate message to the STDOUT and predefined log file on Host machine, then finishes.

Script is able to print log messages into STDOUT and log file on Host machine mounted as volume to the Pod (see func **log()**).
>In case log is not available, script will only prints log messages to STDOUT

-------------------------
### Choose testing envinronment:

Considering that I do not need a real cluster with a few nodes for this task, I've decided to choose **minikube**, as it is:
- simple (in comparison to KIND);
- lightweight (one node Kubernetes cluster that can be used for test purposes).

Also, it has a large community, so most probably I'll be able to find a solution to any issue that I'll get with installation and deployment.

-------------------------
### How to make a Kubernetes deployment:

**1. Install docker according to the official documentation:**

https://docs.docker.com/engine/install/ubuntu/

```
> sudo docker version
Client: Docker Engine - Community
 Version:           20.10.5
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        55c4c88
 Built:             Tue Mar  2 20:18:15 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.5
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       363e9a8
  Built:            Tue Mar  2 20:16:12 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.4
  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e
 runc:
  Version:          1.0.0-rc93
  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**2. Install hypervisor:**

I've decided to use VirtualBox: https://www.virtualbox.org/wiki/Downloads as I've already a hands on experiance with it.
```
> vboxmanage --version
5.1.38_Ubuntur122592
```

**3. Install minikube according to official documentation:**
https://kubernetes.io/ru/docs/tasks/tools/install-minikube/

- install kubectl - commandline utility that uses Kubernetes API:
```
> kubectl version --client
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.5", GitCommit:"6b1d87acf3c8253c123756b9e61dac642678305f", GitTreeState:"clean", BuildDate:"2021-03-18T01:10:43Z", GoVersion:"go1.15.8", Compiler:"gc", Platform:"linux/amd64"}
```

- install minikube:
```
minikube version
minikube version: v1.18.1
commit: 09ee84d530de4a92f00f1c5dbc34cead092b95bc
```

**4. Start minikube:**
```
minikube start
* minikube v1.18.1 on Linuxmint 18.3
* Automatically selected the virtualbox driver. Other choices: none, ssh
* Downloading VM boot image ...
    > minikube-v1.18.0.iso.sha256: 65 B / 65 B [-------------] 100.00% ? p/s 0s
    > minikube-v1.18.0.iso: 212.99 MiB / 212.99 MiB [ 100.00% 10.94 MiB p/s 19s
* Starting control plane node minikube in cluster minikube
* Downloading Kubernetes v1.20.2 preload ...
    > preloaded-images-k8s-v9-v1....: 491.22 MiB / 491.22 MiB  100.00% 10.74 Mi
* Creating virtualbox VM (CPUs=2, Memory=3800MB, Disk=20000MB) ...
* Preparing Kubernetes v1.20.2 on Docker 20.10.3 ...
  - Generating certificates and keys ...
  - Booting up control plane ...
  - Configuring RBAC rules ...
* Verifying Kubernetes components...
  - Using image gcr.io/k8s-minikube/storage-provisioner:v4
* Enabled addons: storage-provisioner, default-storageclass
* Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

- verify that minikube is up and running:
```
# Gets list of Kubernetes nodes with state and start time:
kubectl get nodes
NAME       STATUS   ROLES                  AGE   VERSION
minikube   Ready    control-plane,master   48m   v1.20.2
```

```
# List all pods in ps output format:
kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   50m
```

```
# List all pods in all namespaces (including system namespaces):
kubectl get pods -A
NAMESPACE              NAME                                        READY   STATUS    RESTARTS   AGE
kube-system            coredns-74ff55c5b-48x87                     1/1     Running   0          2m35s
kube-system            etcd-minikube                               1/1     Running   0          2m42s
kube-system            kube-apiserver-minikube                     1/1     Running   0          2m42s
kube-system            kube-controller-manager-minikube            1/1     Running   0          2m42s
kube-system            kube-proxy-kdzq5                            1/1     Running   0          2m34s
kube-system            kube-scheduler-minikube                     1/1     Running   0          2m42s
kube-system            storage-provisioner                         1/1     Running   0          2m48s
```

As you may see I've all resources up and running inside test minikube deployment.

Now, you are ready to configure Kubernetes running TFTP monitoring script.

-------------------------
### Deploy and run monitoring script using CronJob controller

**1. Mount Host directory that stores system log to minikube VM:**

In order to allow Pods access to the host machine file system (FS), we should mount it first as a shared directory to minikube VM.

> NOTE: in this test task the same mount point will be used to store monitoring script logs for history,
as it is not quite efficient to use spec.successfulJobsHistoryLimit and spec.failedJobsHistoryLimit of CronJob that will start pods with the scipt to keep only script log messages.

> NOTE: before mount host machine directory, create log file for monitoring script and assigh write permissions to all users and groups:

```
mkdir -p /var/log/mon_logs/
touch /var/log/mon_logs/tftp_monitor.log
chmod 666 /var/log/mon_logs/tftp_monitor.log
```

Mount Host machine direstory to minikube VM:
```
minikube stop
minikube start --mount --mount-string="/var/log:/host_logs"

# you may use the following approach as well, but it is not quite convinient as it cannot be run in the background:
minikube mount /var/log:/host_logs --mode=0755
```

Ensure that required logs are available in minikube VM:
```
# ssh to minikube VM:
minikube ssh

# ensure that logs are available:
$ ls -lah /host_logs/syslog
-rw-r----- 1 docker docker 73K Mar 31 20:34 /host_logs/syslog

$ ls -lah /host_logs/mon_logs/tftp_monitor.log
-rw-rw-rw- 1 docker docker 48K Mar 30 22:28 /host_logs/mon_logs/tftp_monitor.log
```

**2. Create ConfigMap using created monitoring script:**

In order to run script inside a Pod that starts container, there are two options:
1. Add your script into the container using Docker file. Then you will be able to build image from that container and configure Pod in Kubernetes using this image that will include your custom script.
2. Add script inside of configmap that will be mounted as a file in Pod with executable parameters upon Pod creation by CronJob.

I've chosen the second approach as it supports making changes to the script on the fly without the necessity of making a new version of Docker image every time I would like to make changes to the script.

**Create ConfigMap to mount the script in future**
```
# Create configmap
cd /data/kube_lab/test_case/
kubectl create configmap tftp-monitor --from-file=tftp-monitor.sh
configmap/tftp-monitor created
 
# Check the actual look of configmap
kubectl describe configmaps tftp-monitor
 
# You can edit configmap on fly:
# useful for small corrections
kubectl edit configmaps tftp-monitor
 
# Propagate changes to Kubernetes on fly without deleting created configmap
# in this case you won't need to use built-in editor in kubectl
# it is useful if you update monitoring scripts repository using git and would like to upload new version to the file as a configmap:
kubectl create configmap tftp-monitor --from-file=tftp-monitor.sh -o yaml --dry-run=client|kubectl replace -f -
```

**Create CronJob resource that will execute script that is added to ConfigMap:**
```
# API version where cronjobs are introduced should be specified here:
# https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/ (see FEATURE STATE)
apiVersion: batch/v1beta1
# Kind name to Create CronJob resource
kind: CronJob
metadata:
  name: tftp-monitor
# lables here and below in container description are used to simplify CronJob management and all resources created by this CronJob
  labels:
    app: tftp-monitor
spec:
# Schedule Job execution every 1 min
# The schedule for CronJob should be set in conjuction with $nlines in tftp-monitor.sh script.
  schedule: "*/1 * * * *"
# Number of succefully completed pods saved by crobjob, so admin can check its logs inside of kubernetes
  successfulJobsHistoryLimit: 6
# Number of succefully completed pods saved by crobjob, so admin can check its logs inside of kubernetes
  failedJobsHistoryLimit: 6
  jobTemplate:
    spec:
# If restartPolicy is not Never, it shows the number of times failed Pod will be restarted inside of a Job, before it will be considered as failed.
      backoffLimit: 2
# Once a Job is running for 60 sec, all of its running Pods will be terminated and Job will become failed even if backoffLimit is not reached
      activeDeadlineSeconds: 60
      template:
        metadata:
          labels:
            app: tftp-monitor
        spec:
          containers:
          - name: tftp-monitor
# I've decided to use busybox docker image as an execution env for the script. It is lightweight container and contains all required utilities for monitoring script
            image: busybox
# Define volumes that should be mount to the container
# host-logs - volume that contains system log that should be checked by the script and log file for script
# tftp-monitor - volume that contains script executable
            volumeMounts:
              - name: host-logs
                mountPath: /host_logs/
              - name: tftp-monitor
                mountPath: /mon_scripts/
# Specifying env variables required for scipt execution:
# I've decided to use these to show one more way of defining variables for the script that is executed inside of container.
# Env variables are useful if you run several scripts in one container. In that case if you need to check some variable used in all the script, you don't need to update all your 
# scripts. Instead, you can simply modify variables inside a spec file:
            env:
              - name: NODE_IP
                value: "192.168.99.1"
              - name: REMOTE_SMTP_IP
                value: "192.168.1.23"
              - name: REMOTE_SMTP_PORT
                value: "25"
            command: ["/mon_scripts/tftp-monitor.sh"]
          restartPolicy: OnFailure
# Define volumes that should be provided to Pod created by Job:
          volumes:
# host-logs - should be hostPath type to mount directory from Host node to allow Pod: read data from system log and write data to monitoring log
            - name: host-logs
              hostPath:
                path: /host_logs/
# tftp-monitor - should be configMap type, to inject executable script into a Pod created by Job. Esential point to get script executable is to specify defaultMode to make script executable for owner of the file (docker user inside of container).
            - name: tftp-monitor
              configMap:
                name: tftp-monitor
                defaultMode: 0744
```

**Check script execution:**

To ensure that CronJob resource is created successfully use the following commands:
```
kubectl get cronjobs
NAME                         SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/tftp-monitor   */5 * * * *   False     0        <none>          14s

# If you run several resources and want to get only status of tftp monitor job, use selector with appropriate label app=tftp-monitor that was specified in tftp-monitor.yaml file during creation:
kubectl get cronjobs --selector=app=tftp-monitor
NAME                         SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/tftp-monitor   */5 * * * *   False     0        <none>          14s
```

In order to see all resources related to tftp-monitor cronjob use the following command:
```
kubectl get all --selector=app=tftp-monitor

NAME                                READY   STATUS      RESTARTS   AGE
pod/tftp-monitor-1617226500-w6d5z   0/1     Completed   0          7m37s
pod/tftp-monitor-1617226800-v4fc9   0/1     Completed   0          2m33s

NAME                                COMPLETIONS   DURATION   AGE
job.batch/tftp-monitor-1617226500   1/1           5s         7m37s
job.batch/tftp-monitor-1617226800   1/1           4s         2m33s

NAME                         SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/tftp-monitor   */5 * * * *   False     0        2m42s           10m
```

As you can see during execution CronJob creates the corresponding Job according to schedule.
Appropriate Job creates the corresponding Pod that executes script mounted from ConfigMap specified as a volume in tftp-monitor.yaml.

Using the above command you can see a status of executed Job/Pod - **Completed** means that Job/Pod has been finished successfully, other states that you may see:
**Error** - pod was executed, but command finished with non-zero error code;
**CrashLoopBackOff** - Pod is tried to start, then finished with error, that started again;
**Running** - Pod is running

You can check everything that the monitoring script prints to STDOUT during execution inside a Pod:
```
# logs can be retrieved using kubernetes API for all runs in a batch:
# get all pods names with lable app=tftp-monitor, print only names:
pods=$(kubectl get pods --selector=app=tftp-monitor --output=jsonpath={.items[*].metadata.name})
for pod in ${pods[@]}; do kubectl logs $pod; done

# or you can retrieve log for some partticular pod simply typing:
kubectl logs <pod_name>
```

Considering that tftp-monitor.sh also prints data to log located in /var/log/mon_logs/tftp_monitor.log (by default) you can check this log on the Host machine.
It will contain all history for every script run.

Example of log output when Brute-force is not detected:
```
kubectl logs tftp-monitor-1617226500-w6d5z
Mar 31 21:35:09: Start script /mon_scripts/tftp-monitor.sh
Mar 31 21:35:09: Checked file: /host_logs/syslog exists. Proceed with TFTP check.
Mar 31 21:35:09: Brute-force atteampts have not been detected!
```

Example of log output when Brute-force is detected:
```
Mar 31 22:00:07: Start script /mon_scripts/tftp-monitor.sh
Mar 31 22:00:07: Checked file: /host_logs/syslog exists. Proceed with TFTP check.
Mar 31 22:00:07: Brute-force atteampts have been detected!
Mar 31 22:00:07: Here is the statistics:
Mar 31 22:00:07:       8 192.168.1.23
Mar 31 22:00:07: Checking if remote SMPT 192.168.1.23:25 is available.
192.168.243.38 (192.168.1.23:25) open
Mar 31 22:00:07: Composing and sending email alert.
Mar 31 22:00:08: Email has been sent.
```

Email example that recepient will get when script found log messages in the system log related to brute-force attempt:
```
Sbj: TFPT brute-force is detected on 192.168.99.1
--
Hi,

Someone tried to brute-force TFTP connection on 192.168.99.1.

Here is the report:
      8 192.168.1.23
```

To check script workflow you may reproduce a brute-force attempt on TFTP server running on Host machine.
In order to do that, execute the following one-liner outside of Host machine:
```
for i in `seq 1 20`; do tftp 192.168.233.119 -c get test.txt; done
```

-------------------------
### Uninstall:

In order to uninstall created jobs and configmap it is enough to run:
```
#delete cronjob - it will remove all created jobs and pods:
kubectl delete cronjobs tftp-monitor
#delete configmap:
kubectl delete configmaps tftp-monitor
```
